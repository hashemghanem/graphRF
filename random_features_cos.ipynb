{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian kernel Approximation\n",
    "### In this code we approximate the Gaussian kernel of two graphs by the dot product of two k-random features consinus vectors, each belongs to the corresponding graph\n",
    "### Datasets used: mutag, SBM\n",
    "### Graph sampling technique used in this code: Random Walk With flyback \n",
    "### Machine learning algo: SVM with kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grakel as gk\n",
    "import networkx as nx\n",
    "import Graph_Sampling as gs\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from grakel.datasets import fetch_dataset\n",
    "from random import random\n",
    "from grakel import Graph\n",
    "from grakel.kernels import ShortestPath\n",
    "from sklearn.utils import shuffle \n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## graph building and sampling Visualization\n",
    "### this is to be done by networkx (and matplotlib package for visualization) with the purpose of testing the sampling technique via Graph_Sampling package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.complete_graph(20)\n",
    "nx.draw(G,with_labels=True)\n",
    "plt.show()\n",
    "p=0.5\n",
    "object = gs.SRW_RWF_ISRW()             \n",
    "#sampled_subgraph = object.random_walk_sampling_simple(G,8)\n",
    "sampled_subgraph = object.random_walk_sampling_with_fly_back(G,5,p)\n",
    "nx.draw(nx.Graph(sampled_subgraph),with_labels=True)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Features Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sampling(G,nodes_num):\n",
    "    return G.subgraph(random.sample(G.nodes(), nodes_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB : might be good to decouple \"sampling\" and \"feature computing\" in different classes\n",
    "def random_feature_flyback_sampling(G,nodes_num, features_num, samples_num, p_flyback, feature_mat):\n",
    "    '''\n",
    "    output: random features vector of G computed as the average of the \n",
    "            random feature vectors of its subgraphs\n",
    "            sampling method: random walk with fly back\n",
    "    input: graph G\n",
    "            number of features to be computed\n",
    "            number of subsamples to be considered\n",
    "            feature_mat: random features projection matrix\n",
    "            pdf: the probability dist function of each of the frequencies included in feature_mat (each row is an freq)\n",
    "    '''\n",
    "    object=gs.SRW_RWF_ISRW();\n",
    "    for _ in range (samples_num):\n",
    "        sampled_subgraph=object.random_walk_sampling_with_fly_back(G,nodes_num,p_flyback)\n",
    "        adjacency=nx.to_numpy_matrix(sampled_subgraph).flatten().T if _==0 \\\n",
    "                  else np.append(adjacency,nx.to_numpy_matrix(sampled_subgraph).flatten().T,axis=1)\n",
    "    random_feature=np.cos(feature_mat.dot(adjacency))       # theta is the product of w with Adacency matrix\n",
    "    return np.mean(random_feature,axis=1)\n",
    "\n",
    "def random_feature_simple_sampling(G,nodes_num, features_num, samples_num, feature_mat):\n",
    "    '''\n",
    "    output: random features vector of G computed as the average of the \n",
    "            random feature vectors of its subgraphs\n",
    "            sampling method: random walk with fly back\n",
    "    input: graph G\n",
    "            number of features to be computed\n",
    "            number of subsamples to be considered\n",
    "            feature_mat: random features projection matrix\n",
    "            pdf: the probability dist function of each of the frequencies included in feature_mat (each row is an freq)\n",
    "    '''\n",
    "    for _ in range (samples_num):\n",
    "        sampled_subgraph=simple_sampling(G,nodes_num)\n",
    "        adjacency=nx.to_numpy_matrix(sampled_subgraph).flatten().T if _==0 \\\n",
    "                  else np.append(adjacency,nx.to_numpy_matrix(sampled_subgraph).flatten().T,axis=1)\n",
    "    temp = feature_mat.dot(adjacency)\n",
    "    random_feature=np.concatenate((np.cos(temp),np.sin(temp)))       # theta is the product of w with Adacency matrix\n",
    "    return np.mean(random_feature,axis=1)\n",
    "\n",
    "\n",
    "def random_features_projection_matrix(sigma,nodes_num, features_num):\n",
    "    '''\n",
    "    this function returns the random feature projection matrix that corresponds to Gaussian kernel\n",
    "    output: feature_mat: random features projection matrix\n",
    "            pdf: the probability dist function of each of the frequencies included in feature_mat (each row is an freq)\n",
    "    input: sigma : the deviation of the normal distribution\n",
    "           nodes_num: the number of nodes to be sampled from the graph ( used in feature_mat shape)\n",
    "           feature_num: number of frequencies to be considered\n",
    "    '''\n",
    "    norm_dist=stats.norm(0,sigma)    # the distribution of frequencies ( Gaussian kernel)\n",
    "    feature_mat=sigma*np.random.randn(features_num,nodes_num**2) \n",
    "    # calculating the probailiy of each of the resulting frequencies\n",
    "    for i in range (nodes_num**2):pdf=norm_dist.pdf(feature_mat[:,0]) if i==0 else pdf*norm_dist.pdf(feature_mat[:,i])\n",
    "    pdf=pdf/max(pdf)\n",
    "    return feature_mat, pdf\n",
    "\n",
    "nodes_num, features_num, samples_num, p_flyback, sigma=6, 200, 1000, 0.5, 10\n",
    "\n",
    "proj_matrix,pdf=random_features_projection_matrix(sigma,nodes_num, features_num)\n",
    "#print(proj_matrix)\n",
    "#print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutag dataset\n",
    "Gnx_train=[];\n",
    "Gnx_test=[];\n",
    "MUTAG = fetch_dataset(\"MUTAG\", verbose=False,as_graphs=False)\n",
    "G, y = MUTAG.data, MUTAG.target\n",
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.1, random_state=42)\n",
    "for i in range(len(G_train)):\n",
    "    g_current=nx.Graph(list(G_train[i][2]));\n",
    "    g_current.add_nodes_from(G_train[i][1])\n",
    "    Gnx_train.append(g_current)\n",
    "for i in range(len(G_test)):\n",
    "    g_current=nx.Graph(list(G_test[i][2]));\n",
    "    g_current.add_nodes_from(G_test[i][1])\n",
    "    Gnx_test.append(g_current)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random dataset\n",
    "G = list()\n",
    "y = list()\n",
    "probs = [0.25, 0.5, 0.75]\n",
    "for i in range(len(probs)):\n",
    "    for j in range(5, 55):\n",
    "            edges = list()\n",
    "            for n1 in range(j):\n",
    "                    for n2 in range(n1+1, j):\n",
    "                            if random() <= probs[i]:\n",
    "                                    edges.append((n1, n2))\n",
    "                                    edges.append((n2, n1))\n",
    "\n",
    "            G.append(nx.Graph(edges))\n",
    "            y.append(i)\n",
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.1, random_state=42)\n",
    "Gnx_train,Gnx_test=G_train,G_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SBM dataset generator\n",
    "Graphs_num,nodes_per_graph,block_size=100,102,34\n",
    "blocks_num=int(nodes_per_graph/block_size)\n",
    "sizes=[block_size]*blocks_num\n",
    "fraction=0.4;\n",
    "avg_deg=fraction*block_size;\n",
    "G,y=[],[]\n",
    "for i in range (Graphs_num):\n",
    "    p_in=(fraction/3)*(1+i/(Graphs_num/2));\n",
    "    p_out=(avg_deg-(block_size-1)*p_in)/(nodes_per_graph-block_size)\n",
    "    p=p_out*np.ones([blocks_num]*2)+(p_in-p_out)*np.eye(blocks_num)\n",
    "    G.append(nx.stochastic_block_model(sizes, p, seed=0))\n",
    "    y.append(-1 if i<Graphs_num/2 else 1)\n",
    "G, y = shuffle(G, y, random_state=0)\n",
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.1, random_state=42)\n",
    "Gnx_train,Gnx_test=G_train,G_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SBM dataset generator (here only one SB Model per class)\n",
    "Graphs_num,nodes_per_graph,block_size=100,102,34\n",
    "blocks_num=int(nodes_per_graph/block_size)\n",
    "sizes=[block_size]*blocks_num\n",
    "fraction=1;\n",
    "avg_deg=fraction*block_size;\n",
    "G,y=[],[]\n",
    "p_in=(fraction/3);\n",
    "p_out=(avg_deg-(block_size-1)*p_in)/(nodes_per_graph-block_size)\n",
    "p=p_out*np.ones([blocks_num]*2)+(p_in-p_out)*np.eye(blocks_num)\n",
    "for i in range (Graphs_num):\n",
    "    G.append(nx.stochastic_block_model(sizes, p, seed=0))\n",
    "    y.append(0)\n",
    "print(p)\n",
    "p_in=2*(fraction/3);\n",
    "p_out=(avg_deg-(block_size-1)*p_in)/(nodes_per_graph-block_size)\n",
    "p=p_out*np.ones([blocks_num]*2)+(p_in-p_out)*np.eye(blocks_num)\n",
    "for i in range (Graphs_num):\n",
    "    G.append(nx.stochastic_block_model(sizes, p, seed=0))\n",
    "    y.append(1)\n",
    "print(p)\n",
    "G, y = shuffle(G, y, random_state=0)\n",
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.1, random_state=42)\n",
    "Gnx_train,Gnx_test=G_train,G_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the kernel and training the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flyback sampling: can be long !!\n",
    "for i in range(len(Gnx_train)):\n",
    "    if i==0:\n",
    "        random_features_train=random_feature_flyback_sampling(Gnx_train[i],nodes_num, features_num, \n",
    "                                                              samples_num, p_flyback, proj_matrix)\n",
    "    else:\n",
    "        random_features_train=np.append(random_features_train,\n",
    "                                        random_feature_flyback_sampling(Gnx_train[i],nodes_num, \n",
    "                                                                        features_num, samples_num,\n",
    "                                                                        p_flyback, proj_matrix),axis=1)\n",
    "    print(i)\n",
    "for i in range(len(Gnx_test)):\n",
    "    if i==0:\n",
    "        random_features_test=random_feature_flyback_sampling(Gnx_test[i],nodes_num, features_num, \n",
    "                                                              samples_num, p_flyback, proj_matrix)\n",
    "    else:\n",
    "        random_features_test=np.append(random_features_test,\n",
    "                                        random_feature_flyback_sampling(Gnx_test[i],nodes_num, \n",
    "                                                                        features_num, samples_num,\n",
    "                                                                        p_flyback, proj_matrix),axis=1)\n",
    "#K_train =random_features_train.T.dot(np.multiply(pdf.reshape(features_num,1),random_features_train))\n",
    "K_train =random_features_train.T.dot(random_features_train)\n",
    "#K_test =random_features_test.T.dot(np.multiply(pdf.reshape(features_num,1),random_features_train))\n",
    "K_test =random_features_test.T.dot(random_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "# simple sampling\n",
    "for i in range(len(Gnx_train)):\n",
    "    if i==0:\n",
    "        random_features_train=random_feature_simple_sampling(Gnx_train[i],nodes_num, features_num, \n",
    "                                                              samples_num, proj_matrix)\n",
    "    else:\n",
    "        random_features_train=np.append(random_features_train,\n",
    "                                        random_feature_simple_sampling(Gnx_train[i],nodes_num, \n",
    "                                                                        features_num, samples_num,\n",
    "                                                                        proj_matrix),axis=1)\n",
    "    print(i)\n",
    "for i in range(len(Gnx_test)):\n",
    "    if i==0:\n",
    "        random_features_test=random_feature_simple_sampling(Gnx_test[i],nodes_num, features_num, \n",
    "                                                              samples_num, proj_matrix)\n",
    "    else:\n",
    "        random_features_test=np.append(random_features_test,\n",
    "                                        random_feature_simple_sampling(Gnx_test[i],nodes_num, \n",
    "                                                                        features_num, samples_num,\n",
    "                                                                        proj_matrix),axis=1)\n",
    "#K_train =random_features_train.T.dot(np.multiply(pdf.reshape(features_num,1),random_features_train))\n",
    "K_train =random_features_train.T.dot(random_features_train)\n",
    "#K_test =random_features_test.T.dot(np.multiply(pdf.reshape(features_num,1),random_features_train))\n",
    "K_test =random_features_test.T.dot(random_features_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.74%\n",
      "[ 1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1  1  1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"precomputed\")\n",
    "clf.fit(K_train, y_train)\n",
    "y_pred = clf.predict(K_test)\n",
    "\n",
    "# Computes and prints the classification accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit...\n",
      "Accuracy: 94.74%\n",
      "[ 1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1  1  1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# the solution: model selection\n",
    "C_range = 10. ** np.arange(-2, 10)\n",
    "param_grid = dict(C=C_range)\n",
    "grid = GridSearchCV(SVC(kernel='rbf', gamma='auto'),\n",
    "                    param_grid=param_grid, cv=StratifiedKFold())\n",
    "print('Fit...')\n",
    "grid.fit(K_train, y_train)\n",
    "# Training error\n",
    "y_pred = grid.predict(K_test)\n",
    "\n",
    "# Computes and prints the classification accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
