{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4gl_HqV-Tgf"
   },
   "outputs": [],
   "source": [
    "#cu101 \n",
    "!pip install torch-geometric \\\n",
    "  torch-sparse==latest+cu101 \\\n",
    "  torch-scatter==latest+cu101 \\\n",
    "  torch-cluster==latest+cu101 \\\n",
    "  -f https://pytorch-geometric.com/whl/torch-1.4.0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iqmxopj3wL4"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import torch\n",
    "from matplotlib import pyplot as plt \n",
    "#from torch_geometric.datasets import Entities \n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GINConv, global_add_pool, GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import convert\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "80fAb41VNGWi",
    "outputId": "7cc4e241-3754-4655-ac68-53f8c158ccd7"
   },
   "outputs": [],
   "source": [
    "class dataset_loading:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    #SBM generator\n",
    "    def generate_SBM(self,Graphs_num=300,nodes_per_graph=60,block_size=10,fraction=0.3,mult_factor=2,avg_deg=10,test_size=0.2):\n",
    "        blocks_num=int(nodes_per_graph/block_size)\n",
    "        sizes=[block_size]*blocks_num\n",
    "        G,y=[],[]\n",
    "        for i in range (Graphs_num):                  \n",
    "            p_in=fraction  if i <Graphs_num/2 else fraction*mult_factor\n",
    "            p_out=(avg_deg-(block_size-1)*p_in)/(nodes_per_graph-block_size)\n",
    "            p=p_out*np.ones([blocks_num]*2)+(p_in-p_out)*np.eye(blocks_num)\n",
    "            #print(p_in,p_out)\n",
    "            G.append(nx.stochastic_block_model(sizes, p))\n",
    "            y.append(0 if i<Graphs_num/2 else 1)            \n",
    "        G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=test_size)\n",
    "        return (G_train,y_train),(G_test,y_test)\n",
    "\n",
    "mult_factor=2 # here the code is not prepared yet to handle a vector of values as in the main code\n",
    "(Gtr,ytr),(Gts,yts)=dataset_loading().generate_SBM(mult_factor=mult_factor)     \n",
    "#transforming the dataset to Torch_geometry framework \n",
    "for i,g in enumerate (Gtr):\n",
    "  dg=list(g.degree(g.nodes))\n",
    "  dg=dict([(i,[j]) for (i,j) in dg])\n",
    "  nx.set_node_attributes(g,dg,'x')\n",
    "Gtr=[convert.from_networkx(g) for g in Gtr]\n",
    "for i,g in enumerate (Gtr): g.y=torch.tensor([ytr[i]],dtype=torch.long)\n",
    "\n",
    "for i,g in enumerate (Gts):\n",
    "  dg=list(g.degree(g.nodes))\n",
    "  dg=dict([(i,[j]) for (i,j) in dg])\n",
    "  nx.set_node_attributes(g,dg,'x')\n",
    "Gts=[convert.from_networkx(g) for g in Gts]\n",
    "for i,g in enumerate (Gts): g.y=torch.tensor([yts[i]], dtype=torch.long)\n",
    "\n",
    "test_dataset = Gts                   \n",
    "train_dataset = Gtr\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        num_features=1\n",
    "        dim = 32\n",
    "        hidden=dim\n",
    "        num_layers=4\n",
    "        num_classes=2\n",
    "        self.conv1 = GCNConv( num_features, hidden)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden)                  \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bn=torch.nn.ModuleList()\n",
    "        for i in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden, hidden))\n",
    "            self.bn.append( torch.nn.BatchNorm1d(hidden) )\n",
    "        self.lin1 = Linear(hidden, hidden)\n",
    "        self.lin2 = Linear(hidden,  num_classes)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim)                  #######################################################\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        #x, edge_index, batch = data.x, data.edge_index, data.batch          #############################################3\n",
    "        x = F.relu(self.conv1(x.float(), edge_index))\n",
    "        x=self.bn1(x)\n",
    "        for i,conv in enumerate(self.convs):\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "            x=self.bn[i](x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        #x = F.dropout(x, p=0.1, training=self.training)     #######################################################################3\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    if epoch == 51:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.1 * param_group['lr']\n",
    "    \n",
    "    for param_group in optimizer.param_groups: pass\n",
    "        #param_group['lr'] =  param_group['lr']/(1+0.1*epoch)\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        #print(data.x)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 1000):\n",
    "    train_loss = train(epoch)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    #test_acc = 0\n",
    "    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "          'Train Acc: {:.1f}%, Test Acc: {:.0f}%'.format(epoch, train_loss,\n",
    "                                                       100*train_acc, 100*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "6QxOPZJeVlYZ",
    "outputId": "a1ffc30c-b501-4871-b086-01e16c171f1c"
   },
   "outputs": [],
   "source": [
    "# do not read this cell, it is unimportant. I just tried some things. \n",
    "\n",
    "a=TUDataset(root=\".\", name=\"MUTAG\").shuffle()\n",
    "print(len(a))\n",
    "print(a[0].keys)\n",
    "print(a[0].y)\n",
    "print(a[100].y)\n",
    "a=convert.to_networkx(a[0],node_attrs='x')\n",
    "print()\n",
    "color = nx.get_node_attributes(a, 'x')\n",
    "print(a.nodes[0]['x'])\n",
    "#print(a.nodes(data=True))\n",
    "a=convert.from_networkx(a)\n",
    "print(type(a))\n",
    "print(a.y)\n",
    "a.y=1\n",
    "print(a.y)\n",
    "\n",
    "\n",
    "\n",
    "#nx.draw(a)\n",
    "#plt. show()\n",
    "dataset = TUDataset('.', name='MUTAG').shuffle()\n",
    "test_dataset = dataset[:1]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "print(type(test_dataset))\n",
    "print(dataset[0].y)\n",
    "print(type(dataset[0]))\n",
    "for data in test_loader:\n",
    "  data = data.to(device)\n",
    "  print(data.x.dtype)\n",
    "print(dataset.num_features)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
